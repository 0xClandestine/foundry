name: Foundry Benchmarks

on:
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      pr_number:
        description: "PR number to comment on (optional)"
        required: false
        type: string
      versions:
        description: "Comma-separated list of Foundry versions to benchmark (e.g., stable,nightly,v1.0.0)"
        required: false
        type: string
        default: "stable,nightly"
      repos:
        description: "Comma-separated list of repos to benchmark (e.g., ithacaxyz/account:main,Vectorized/solady)"
        required: false
        type: string
        default: "ithacaxyz/account:v0.3.2,Vectorized/solady:v0.1.22"

permissions:
  contents: write
  pull-requests: write

jobs:
  benchmark:
    name: Run Foundry Benchmarks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: |
            ./

      - name: Install Foundry
        run: |
          curl -L https://foundry.paradigm.xyz | bash
          echo "$HOME/.foundry/bin" >> $GITHUB_PATH

      - name: Install hyperfine
        run: |
          wget https://github.com/sharkdp/hyperfine/releases/download/v1.18.0/hyperfine_1.18.0_amd64.deb
          sudo dpkg -i hyperfine_1.18.0_amd64.deb

      - name: Build benchmark binary
        run: cargo build --release --bin foundry-bench

      - name: Run forge test benchmark
        run: |
          VERSIONS="${{ github.event.inputs.versions || 'stable,nightly' }}"
          REPOS="${{ github.event.inputs.repos || 'ithacaxyz/account:v0.3.2,Vectorized/solady:v0.1.22' }}"
          
          ./target/release/foundry-bench --output-dir ./benches --force-install \
            --versions $VERSIONS \
            --repos $REPOS \
            --benchmarks forge_test \
            --output-file forge_test.md

      - name: Run forge build (no cache) benchmark
        run: |
          VERSIONS="${{ github.event.inputs.versions || 'stable,nightly' }}"
          REPOS="${{ github.event.inputs.repos || 'ithacaxyz/account:v0.3.2,Vectorized/solady:v0.1.22' }}"
          
          ./target/release/foundry-bench --output-dir ./benches --force-install \
            --versions $VERSIONS \
            --repos $REPOS \
            --benchmarks forge_build_no_cache \
            --output-file forge_build_no_cache.md

      - name: Run forge build (with cache) benchmark
        run: |
          VERSIONS="${{ github.event.inputs.versions || 'stable,nightly' }}"
          REPOS="${{ github.event.inputs.repos || 'ithacaxyz/account:v0.3.2,Vectorized/solady:v0.1.22' }}"
          
          ./target/release/foundry-bench --output-dir ./benches --force-install \
            --versions $VERSIONS \
            --repos $REPOS \
            --benchmarks forge_build_with_cache \
            --output-file forge_build_with_cache.md

      - name: Combine benchmark results
        run: |
          # Combine all benchmark results into LATEST.md
          echo "# Foundry Benchmark Results" > benches/LATEST.md
          echo "" >> benches/LATEST.md
          echo "Generated at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> benches/LATEST.md
          echo "" >> benches/LATEST.md
          
          # Add each benchmark result if it exists
          for bench in forge_test forge_build_no_cache forge_build_with_cache; do
            if [ -f "benches/${bench}.md" ]; then
              # Skip the header from individual files and append content
              tail -n +2 "benches/${bench}.md" >> benches/LATEST.md
              echo "" >> benches/LATEST.md
            fi
          done

      - name: Commit benchmark results
        if: github.event_name != 'pull_request'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add benches/LATEST.md benches/forge_test.md benches/forge_build_no_cache.md benches/forge_build_with_cache.md
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore(\`benches\`): update benchmark results

            ðŸ¤– Generated with [Foundry Benchmarks](https://github.com/${{ github.repository }}/actions)
            
            Co-Authored-By: github-actions <github-actions@github.com>"
            git push
          fi

      - name: Read benchmark results
        id: benchmark_results
        run: |
          if [ -f "benches/LATEST.md" ]; then
            {
              echo 'results<<EOF'
              cat benches/LATEST.md
              echo 'EOF'
            } >> $GITHUB_OUTPUT
          else
            echo 'results=No benchmark results found.' >> $GITHUB_OUTPUT
          fi

      - name: Comment on PR
        if: github.event.inputs.pr_number != '' || github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = ${{ github.event.inputs.pr_number || github.event.pull_request.number }};
            const benchmarkResults = `${{ steps.benchmark_results.outputs.results }}`;

            const comment = `## ðŸ“Š Foundry Benchmark Results

            <details>
            <summary>Click to view detailed benchmark results</summary>

            ${benchmarkResults}

            </details>

            ---

            ðŸ¤– This comment was automatically generated by the [Foundry Benchmarks workflow](https://github.com/${{ github.repository }}/actions).

            To run benchmarks manually: Go to [Actions](https://github.com/${{ github.repository }}/actions/workflows/benchmarks.yml) â†’ "Run workflow"`;

            github.rest.issues.createComment({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });